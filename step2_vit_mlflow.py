# step2_vit_mlflow.py
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import numpy as np
import mlflow
import mlflow.pytorch
from transformers import ViTForImageClassification
import os
import time

# 1. ì„¤ì • (GPU ê°•ì œ ì‚¬ìš©)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ğŸš€ Device: {device}")

if device.type == 'cpu':
    print("âš ï¸ ê²½ê³ : GPUê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤! PyTorchê°€ CUDA ë²„ì „ìœ¼ë¡œ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
else:
    print(f"ğŸ”¥ GPU ê°€ì† í™œì„±í™”: {torch.cuda.get_device_name(0)}")
    print("   (RTX 5060 Tiì˜ í˜ì„ ë³´ì—¬ì¤˜!)")

if not os.path.exists('results'): os.makedirs('results')

# 2. ë°ì´í„° ì¤€ë¹„
# ViT ì…ë ¥ í¬ê¸°(224x224)ì— ë§ê²Œ ë³€í™˜
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.Grayscale(num_output_channels=3),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

print("ğŸ“¥ ViTìš© ë°ì´í„° ë¡œë“œ ì¤‘...")
train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)

# 3. ëª¨ë¸ ì •ì˜
def get_vit_model():
    model = ViTForImageClassification.from_pretrained(
        'google/vit-base-patch16-224',
        num_labels=10,
        ignore_mismatched_sizes=True
    )
    # ğŸ”¥ [GPU ì „ëµ] Full Fine-tuning
    # ëª¨ë¸ì˜ ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ í•™ìŠµì‹œí‚´ (ì •í™•ë„ ìƒìŠ¹ ê¸°ëŒ€)
    return model.to(device)

def train_and_log(seed):
    run_name = f"ViT_Full_Tuning_Seed_{seed}"
    
    with mlflow.start_run(run_name=run_name):
        params = {
            "model_type": "ViT (Full Fine-tuning)",
            "seed": seed,
            "epochs": 1,  # GPUë¼ë„ 1 Epochë©´ ì¶©ë¶„íˆ 99% ì°ìŒ (MNISTê°€ ì‰¬ì›Œì„œ)
            "batch_size": 64, # ë©”ëª¨ë¦¬ 16GBë‹ˆê¹Œ ë„‰ë„‰í•˜ê²Œ
            "learning_rate": 2e-5 # Full Tuningì¼ ë• í•™ìŠµë¥ ì„ ì¢€ ë‚®ê²Œ ì¡ëŠ” ê²Œ êµ­ë£°
        }
        mlflow.log_params(params)
        
        torch.manual_seed(seed)
        train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True, num_workers=4, pin_memory=True)
        test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4, pin_memory=True)
        
        model = get_vit_model()
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])
        
        print(f"Trial {seed+1}/10 í•™ìŠµ ì‹œì‘...")
        model.train()
        for epoch in range(params['epochs']):
            for i, (data, target) in enumerate(train_loader):
                data, target = data.to(device), target.to(device)
                optimizer.zero_grad()
                output = model(data).logits
                loss = criterion(output, target)
                loss.backward()
                optimizer.step()
                
                if i % 10 == 0:
                    print(f"  Step {i}/{len(train_loader)} Loss: {loss.item():.4f}")
            
        # í‰ê°€ (ì „ì²´ ë°ì´í„° ì‚¬ìš©)
        model.eval()
        correct = 0
        with torch.no_grad():
            for data, target in test_loader:
                data, target = data.to(device), target.to(device)
                output = model(data).logits
                pred = output.argmax(dim=1, keepdim=True)
                correct += pred.eq(target.view_as(pred)).sum().item()
        
        acc = 100. * correct / len(test_loader.dataset)
        
        # ë§ˆì§€ë§‰ ì‹œë“œì¼ ë•Œ ëª¨ë¸ ì €ì¥ (ì„œë¹™ìš©)
        if seed == 9:
            torch.save(model.state_dict(), "models/vit_model.pth")
            print("ğŸ’¾ ì„œë¹™ìš© ViT ëª¨ë¸ ì €ì¥ ì™„ë£Œ (models/vit_model.pth)")

        mlflow.log_metric("test_accuracy", acc)
        print(f"Trial {seed+1}/10 (Seed {seed}) : Accuracy = {acc:.2f}%")
        return acc

if __name__ == "__main__":
    mlflow.set_experiment("MNIST_Hypothesis_Testing")
    vit_accuracies = []
    
    # CUDA ì²´í¬
    if not torch.cuda.is_available():
        print("ğŸš¨ ì ê¹! GPU ì¸ì‹ì´ ì•ˆ ë©ë‹ˆë‹¤. ê·¸ëƒ¥ ëŒë¦¬ë©´ ëŠë ¤ìš”!")
        print("  -> pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118")
        print("  ëª…ë ¹ì–´ë¡œ CUDA ë²„ì „ì„ ë‹¤ì‹œ ê¹”ì•„ì•¼ í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.")
    else:
        print("\nğŸ”¬ [ì—°êµ¬ê°€ì„¤ ê²€ì¦] ViT 10íšŒ ë°˜ë³µ ì‹¤í—˜ ì‹œì‘ (GPU Mode On âš¡)...")
        start_time = time.time()
        
        for seed in range(10):
            acc = train_and_log(seed)
            vit_accuracies.append(acc)
        
        end_time = time.time()
        
        np.save("results/vit_accuracies.npy", np.array(vit_accuracies))
        mean_acc = np.mean(vit_accuracies)
        
        print("\n" + "="*40)
        print(f"â±ï¸ ì†Œìš” ì‹œê°„ : {end_time - start_time:.2f}ì´ˆ")
        print(f"âœ… ViT í‰ê·  ì •í™•ë„: {mean_acc:.4f}%")
        print("="*40)